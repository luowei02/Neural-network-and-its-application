{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#HW-1: Regression\n",
    "姓名：罗威   学号：SA24218095\n",
    "\n",
    "##1 概述\n",
    "本次作业旨在构建一个全连接神经网络模型，对波士顿房价进行预测。通过对波士顿房价数据集进行特征筛选、数据预处理，利用PyTorch搭建并训练神经网络模型，最终评估模型在测试集上的性能。\n",
    "\n",
    "####1.1 训练结果总结\n",
    " - 首先，对13组数据进行了标签相关性计算，并在代码中对相关性较低的数据进行筛选，以此降低不相关数据产生的噪声影响。\n",
    " - 对相关性较低的数据组合进行剔除过后，训练结果在测试集上的均方误差为11.9592。\n",
    " - 对先前的代码加入早停策略，使模型在验证集上均方误差不再下降时保存模型并停止训练。通过早停策略训练得到的模型在测试集上的均方误差进一步降低到6.0042。\n",
    "\n",
    "####1.2 软硬件环境\n",
    "（1）系统环境：**Ubuntu 22.04 LTS**\n",
    "（2）语言及框架版本：\n",
    "- `Python`: 3.11.11\n",
    "- `Pytorch`: 2.5.0+cu124\n",
    "- `Pandas`: 2.2.3\n",
    "- `Sklearn`: 1.6.0\n",
    "##2 标签相关性分析\n",
    "利用`pandas`库自带的`corr()`函数进行相关性分析。该函数可以计算出多种相关性系数（pearson、kendall、spearman），默认计算的是皮尔逊系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation coefficients with MEDV:\n",
      "RM         0.695360\n",
      "ZN         0.360445\n",
      "B          0.333461\n",
      "DIS        0.249929\n",
      "CHAS       0.175260\n",
      "AGE       -0.376955\n",
      "RAD       -0.381626\n",
      "CRIM      -0.388305\n",
      "NOX       -0.427321\n",
      "TAX       -0.468536\n",
      "INDUS     -0.483725\n",
      "PTRATIO   -0.507787\n",
      "LSTAT     -0.737663\n",
      "Name: MEDV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('./BostonHousingData.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "correlation_matrix = data.corr()\n",
    "correlation = correlation_matrix['MEDV'].sort_values(ascending=False).drop('MEDV')\n",
    "\n",
    "print(\"The correlation coefficients with MEDV:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关系数的取值范围为[-1,1]，其中系数越接近-1和1的标签，与房价的相关性越高。可以看到，计算出的相关系数中，DIS、CHAS与房价的相关性较低；同时，ZN、B、AGE、RAD、CRIM等的相关性相对也较低。因此，可以逐渐剔除这些相关性低下的标签，让模型获得更好的拟合效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3 全连接神经网络模型设计\n",
    "\n",
    "构建了一个全连接神经网络模型`Regression`，具体结构如下：\n",
    "\n",
    "（1）包含5个有参层，分别为3个全连接层（`nn.Linear`）和2个批量归一化层（`nn.BatchNorm1d`）其中的2个隐藏层均使用`nn.Linear`进行线性变换，接着使用`nn.BatchNorm1d`进行批量归一化，`nn.ReLU`作为激活函数，`nn.Dropout(0.2)`进行正则化，防止过拟合；\n",
    "\n",
    "（2）使用常用的`Adam`优化器来进行参数更新，学习率设置为0.001，权重衰减设置为0.001，有助于模型在训练过程中更快地收敛并防止过拟合；\n",
    "\n",
    "（3）使用均方误差损失函数`nn.MSELoss()`，用于衡量模型预测值与真实值之间的差异。\n",
    "\n",
    "如下结果所示，最佳训练结果在测试集上的均方误差为11.9592。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 95.0033\n",
      "Epoch [20/100], Loss: 25.6044\n",
      "Epoch [30/100], Loss: 28.5615\n",
      "Epoch [40/100], Loss: 13.7481\n",
      "Epoch [50/100], Loss: 125.9341\n",
      "Epoch [60/100], Loss: 72.2138\n",
      "Epoch [70/100], Loss: 29.9736\n",
      "Epoch [80/100], Loss: 95.5638\n",
      "Epoch [90/100], Loss: 20.1719\n",
      "Epoch [100/100], Loss: 176.2024\n",
      "\n",
      "MSE on test dataset: 11.9592\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1.从.xlsx文件中读取数据集\n",
    "data = pd.read_excel('BostonHousingData.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# 2.计算相关系数并通过设置的阈值来筛选数据\n",
    "threshold = 0.5 \n",
    "corre = data.corr()\n",
    "correlation = corre['MEDV'].sort_values(ascending=False)\n",
    "selected_features = correlation[abs(correlation) >= threshold].index.tolist()\n",
    "\n",
    "selected_data = data[selected_features]\n",
    "X = selected_data.drop('MEDV', axis=1).values\n",
    "y = selected_data['MEDV'].values.reshape(-1, 1)\n",
    "\n",
    "# 3.划分训练集和测试集\n",
    "X_train, X_test = X[:450], X[450:]\n",
    "y_train, y_test = y[:450], y[450:]\n",
    "\n",
    "# 4.数据标准化处理、转换格式为pytorch张量\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 5.使用库函数加载数据集\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定义输入数据维度，与阈值设置有关\n",
    "input_size = selected_data.shape[1] - 1\n",
    "\n",
    "# 6.全连接神经网络模型的定义\n",
    "class Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = Regression()\n",
    "\n",
    "# 7. 定义损失函数和优化器\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "# 8. 训练模型：自定义训练次数\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{100}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 9. 模型评估\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        total_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "\n",
    "mse = total_loss / len(test_dataset)\n",
    "\n",
    "print(f'\\nMSE on test dataset: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4 使用早停与模型保存的训练方法\n",
    "\n",
    "对于模型训练，固定的`epoch`使得最终训练得到的模型可能并不是最佳模型。`epoch`过多可能导致模型记忆噪声，造成过拟合。`epoch`不足时模型未充分学习，造成欠拟合。因此，采用较大的`epoch`结合早停策略，可以在模型性能表现最佳时将模型保存下来。\n",
    "\n",
    "早停策略的参数设置如下：\n",
    "\n",
    "`best_val_loss`：初始化为正无穷大，用于记录验证集上的最小损失。\n",
    "\n",
    "`patience`：设定为20，表示当验证集损失在连续20个`epoch`中没有下降时，触发早停机制。\n",
    "\n",
    "`counter`：用于记录验证集损失没有下降的连续`epoch`数量，初始化为0。\n",
    "\n",
    "如下结果所示，最佳训练结果在测试集上的均方误差进一步降低到6.0042。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Train Loss: 417.8493, Val Loss: 545.7247\n",
      "Epoch [20/500], Train Loss: 348.2777, Val Loss: 461.9928\n",
      "Epoch [30/500], Train Loss: 365.9896, Val Loss: 386.1222\n",
      "Epoch [40/500], Train Loss: 420.8316, Val Loss: 315.0311\n",
      "Epoch [50/500], Train Loss: 207.3795, Val Loss: 231.4717\n",
      "Epoch [60/500], Train Loss: 244.2944, Val Loss: 179.0083\n",
      "Epoch [70/500], Train Loss: 193.6992, Val Loss: 133.3739\n",
      "Epoch [80/500], Train Loss: 136.5826, Val Loss: 88.3605\n",
      "Epoch [90/500], Train Loss: 106.8433, Val Loss: 60.4388\n",
      "Epoch [100/500], Train Loss: 29.5513, Val Loss: 36.1021\n",
      "Epoch [110/500], Train Loss: 33.9615, Val Loss: 20.6541\n",
      "Epoch [120/500], Train Loss: 21.0119, Val Loss: 16.6938\n",
      "Epoch [130/500], Train Loss: 15.2447, Val Loss: 10.4564\n",
      "Epoch [140/500], Train Loss: 23.1641, Val Loss: 9.5385\n",
      "Epoch [150/500], Train Loss: 61.7226, Val Loss: 8.8601\n",
      "Epoch [160/500], Train Loss: 14.9008, Val Loss: 8.6332\n",
      "Epoch [170/500], Train Loss: 15.9442, Val Loss: 8.9074\n",
      "Epoch [180/500], Train Loss: 34.8720, Val Loss: 7.9747\n",
      "Early stopping at epoch 186\n",
      "\n",
      "MSE on test dataset: 6.0042\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1.从.xlsx文件中读取数据集\n",
    "data = pd.read_excel('BostonHousingData.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# 2.计算相关系数并通过设置的阈值来筛选数据\n",
    "threshold = 0 \n",
    "corre = data.corr()\n",
    "correlation = corre['MEDV'].sort_values(ascending=False)\n",
    "selected_features = correlation[abs(correlation) >= threshold].index.tolist()\n",
    "\n",
    "selected_data = data[selected_features]\n",
    "X = selected_data.drop('MEDV', axis=1).values\n",
    "y = selected_data['MEDV'].values.reshape(-1, 1)\n",
    "\n",
    "# 3.划分训练集和验证集、测试集\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "# 4.数据标准化处理、转换格式为pytorch张量\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 5.使用库函数加载数据集\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 定义输入数据维度，与阈值设置有关\n",
    "input_size = selected_data.shape[1] - 1\n",
    "\n",
    "# 6.全连接神经网络模型的定义\n",
    "class Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = Regression()\n",
    "\n",
    "# 7. 定义损失函数和优化器\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "\n",
    "# 8. 早停策略参数\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "counter = 0\n",
    "\n",
    "# 9. 训练模型：自定义训练次数\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 验证集评估\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "    val_loss /= len(val_dataset)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'model.pth')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "# 10. 加载最佳模型\n",
    "model.load_state_dict(torch.load('model.pth', weights_only = True))\n",
    "\n",
    "# 11. 模型评估\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        total_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "\n",
    "mse = total_loss / len(test_dataset)\n",
    "\n",
    "print(f'\\nMSE on test dataset: {mse:.4f}')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
